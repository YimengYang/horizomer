{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-click \"Web of Life\" builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qiyun Zhu, 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import tarfile\n",
    "from os import (chdir, close, getcwd, listdir, makedirs,\n",
    "                remove, symlink, wait4, write)\n",
    "from os.path import join, isdir, isfile\n",
    "from tempfile import mkdtemp, mkstemp\n",
    "from copy import deepcopy\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "from skbio import io, TreeNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Configuration():\n",
    "    \"\"\"Configurations of this task.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"Define attributes and their default values.\n",
    "        \"\"\"\n",
    "        # working directory\n",
    "        self.wkdir = '.'\n",
    "\n",
    "        # compute resources\n",
    "        self.cpus = 0  # number of CPU cores to use (0 for all)\n",
    "        self.intermdir = ''  # directory to store intermediate files\n",
    "                             # generated by external programs\n",
    "\n",
    "        # intermediate files and directories\n",
    "        self.genomes_dir = ''  # genome sequences in FASTA format\n",
    "        self.proteins_dir = ''  # protein sequences per genome in FASTA format\n",
    "        self.species_tree_fp = ''  # species tree in Newick format\n",
    "        self.gene_families_dir = ''  # protein sequences per family in FASTA format\n",
    "        self.gene_trees_dir = ''  # gene family trees in Newick format\n",
    "        self.gene_networks_dir = ''  # gene family networks\n",
    "\n",
    "        # external programs and databases\n",
    "        self.py2_env = 'py2'  # Python 2 virtual environment\n",
    "        self.prodigal = 'prodigal'\n",
    "        self.phylophlan = 'phylophlan.py'\n",
    "        self.phylophlan_data_dir = 'data'\n",
    "        self.hmmsearch = 'hmmsearch'\n",
    "        self.pfam_db = 'Pfam-A.hmm.gz'\n",
    "        self.phylomizer = 'python phylomizer.py'\n",
    "        self.muscle = 'muscle'\n",
    "        self.mafft = 'mafft'\n",
    "        self.kalign = 'kalign'\n",
    "        self.t_coffee = 't_coffee'\n",
    "        self.trimal = 'trimal'\n",
    "        self.readal = 'readal'\n",
    "        self.fasttree = 'FastTree'\n",
    "        self.optroot = 'OptRoot'\n",
    "        self.rangerdtl = 'Ranger-DTL'\n",
    "        self.aggregateranger = 'AggregateRanger'\n",
    "\n",
    "        # define datatypes of non-str attributes\n",
    "        self.int_attrs = ['cpus']\n",
    "        self.float_attrs = []\n",
    "        self.bool_attrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_config(config_fp):\n",
    "    \"\"\"Read configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config_fp : str\n",
    "        path to configuration file\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        if configuration file is incorrectly formatted\n",
    "        if configuration file contains invalid keys\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    allowed format of the configuration file:\n",
    "        key = value\n",
    "        key      =      value\n",
    "          key=value\n",
    "        key: value\n",
    "        key:value  # comment\n",
    "        key=\n",
    "        # this is comment\n",
    "    prohibited format of the configuration file:\n",
    "        key = foo = bar\n",
    "        key : foo : bar\n",
    "    \"\"\"\n",
    "    global cfg\n",
    "    with open(config_fp, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split('#')[0].rstrip()\n",
    "            if line:\n",
    "                if '=' in line:\n",
    "                    key, value = [x.strip() for x in line.split('=')]\n",
    "                elif ':' in line:\n",
    "                    key, value = [x.strip() for x in line.split(':')]\n",
    "                if key and hasattr(cfg, key):\n",
    "                    for dtype in 'int', 'float', 'bool':\n",
    "                        if key in getattr(cfg, '%s_attrs' % dtype):\n",
    "                            value = eval('%s(value)' % dtype)\n",
    "                    setattr(cfg, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(cmd, screen=False):\n",
    "    \"\"\"Run a Bash command and display screen output in real time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmd : str\n",
    "        Bash command to benchmark\n",
    "    screen : bool\n",
    "        show screen output in real time\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        return code\n",
    "    \"\"\"\n",
    "    kwargs = {'stdout': PIPE, 'stderr': PIPE} if not screen else {}\n",
    "    p = Popen(cmd, shell=True, **kwargs)\n",
    "    rc = wait4(p.pid, 0)[1]\n",
    "    return rc\n",
    "\n",
    "\n",
    "def bench(cmd, screen=False):\n",
    "    \"\"\"Benchmark the time and memory usage of a Bash command.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmd : str\n",
    "        Bash command to benchmark\n",
    "    screen : bool\n",
    "        show screen output in real time\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resource usage object\n",
    "        resource usage information of the process\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        if return code is not 0\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    definition of resource usage object:\n",
    "        https://docs.python.org/3/library/resource.html#resource.getrusage\n",
    "    three most important attributes:\n",
    "        ru_utime (0) : float\n",
    "            user time in seconds\n",
    "        ru_stime (1) : float\n",
    "            system time in seconds\n",
    "        ru_maxrss (2) : int\n",
    "            maximum resident set size (peak memory usage) in kbytes\n",
    "    \"\"\"\n",
    "    kwargs = {'stdout': PIPE, 'stderr': PIPE} if not screen else {}\n",
    "    p = Popen(cmd, shell=True, **kwargs)\n",
    "    rc, ru = wait4(p.pid, 0)[1:3]\n",
    "    if rc != 0:\n",
    "        raise ValueError('Benchmark failed.')\n",
    "    return ru\n",
    "\n",
    "\n",
    "def run0(cmd):\n",
    "    \"\"\"(obsolete) Run a Bash command and display screen output in real time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmd : str\n",
    "        Bash command to benchmark\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        return code\n",
    "    \"\"\"\n",
    "    p = Popen(cmd, shell=True, stdout=PIPE, stderr=STDOUT)\n",
    "    while True:\n",
    "        line, rc = p.stdout.readline(), p.poll()\n",
    "        if rc is not None:\n",
    "            return rc\n",
    "        if line:\n",
    "            print(line.decode('utf-8').rstrip('\\r\\n'))\n",
    "\n",
    "            \n",
    "def bench0(cmd, screen=False):\n",
    "    \"\"\"(obsolete) Benchmark the time and memory usage of a Bash command.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cmd : str\n",
    "        Bash command to benchmark\n",
    "    screen : bool\n",
    "        show screen output in real time\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of 4 floats\n",
    "        wall (elapsed) time, user time and system time in seconds, maximum\n",
    "        memory usage (resident set size) in kbytes\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        if return code is not 0\n",
    "    \"\"\"\n",
    "    cmd = '$(which time) -f \"%E,%U,%S,%M\" bash -c \"' + cmd + '\"'\n",
    "    p = Popen(cmd, shell=True, stdout=PIPE, stderr=STDOUT)\n",
    "    last_line = ''\n",
    "    while True:\n",
    "        line, rc = p.stdout.readline(), p.poll()\n",
    "        if rc is not None:\n",
    "            if rc != 0:\n",
    "                raise ValueError('Benchmark failed.')\n",
    "            break\n",
    "        if line:\n",
    "            if screen == True:\n",
    "                print(last_line)\n",
    "            last_line = line.decode('utf-8').rstrip('\\r\\n')\n",
    "    wall, usr, sys, ram = last_line.split(',')\n",
    "    l = wall.split(':')\n",
    "    wall, exp = 0.0, 0\n",
    "    while l:\n",
    "        wall += float(l.pop()) * (60 ** exp)\n",
    "        exp += 1\n",
    "    return [wall, float(usr), float(sys), float(ram) / 4]\n",
    "\n",
    "\n",
    "def cat(fname):\n",
    "    \"\"\"Get the proper cat command by file extension name.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        file path to read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        cat command\n",
    "    \"\"\"\n",
    "    cats = {'gz': 'zcat', 'bz2': 'bzcat', 'xz': 'xzcat', 'lz': 'lzcat', 'lzma': 'lzcat'}\n",
    "    ext = fname.split('.')[-1]\n",
    "    return cats[ext] if ext in cats else 'cat'\n",
    "\n",
    "\n",
    "def read(fname):\n",
    "    \"\"\"Read the content of a compressed or regular file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        file path to read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    iterable of str\n",
    "        content of the file\n",
    "    \"\"\"\n",
    "    p = Popen(cat(fname) + ' ' + fname, shell=True, stdout=PIPE, stderr=STDOUT)\n",
    "    return p.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_file(fname):\n",
    "    \"\"\"Test if output file exists.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        file name to be generated in this step\n",
    "        e.g., 'species_tree.nwk' is the file name for the PhyloPhlAn step\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        if target file exists\n",
    "    \"\"\"\n",
    "    global cfg\n",
    "    stem = fname.split('.')[0]\n",
    "    fp = getattr(cfg, '%s_fp' % stem)\n",
    "    if not fp:\n",
    "        fp = join(cfg.wkdir, fname)\n",
    "        setattr(cfg, '%s_fp' % stem, fp)\n",
    "    return isfile(fp)\n",
    "\n",
    "\n",
    "def check_dir(dname):\n",
    "    \"\"\"Test if output directory exists, and create it if not.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dname : str\n",
    "        directory name to be generated in this step\n",
    "        e.g., 'faa' is the dname for the Prodigal step\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        if target directory exists\n",
    "    \"\"\"\n",
    "    global cfg\n",
    "    dp = getattr(cfg, '%s_dir' % dname)\n",
    "    if not dp:\n",
    "        dp = join(cfg.wkdir, dname)\n",
    "        setattr(cfg, '%s_dir' % dname, dp)\n",
    "    if isdir(dp):\n",
    "        return True\n",
    "    else:\n",
    "        makedirs(dp)\n",
    "        return False\n",
    "\n",
    "\n",
    "def write_benchmarks(benchmarks, output_fp):\n",
    "    \"\"\"Write benchmark results to file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    benchmarks : dict of resource usage object(s)\n",
    "        resource usage information per run\n",
    "        each element can be a single object, or an iterable of\n",
    "        multiple objects, in latter case times will be summed\n",
    "        and memory will be the max\n",
    "    output_fp : str\n",
    "        output file path\n",
    "    \"\"\"\n",
    "    with open(output_fp, 'w') as f:\n",
    "        for key, bm in sorted(benchmarks.items()):\n",
    "            utime, stime, maxrss = 0.0, 0.0, 0\n",
    "            if hasattr(bm, 'ru_utime'):\n",
    "                utime, stime, maxrss = bm.ru_utime, bm.ru_stime, bm.ru_maxrss\n",
    "            else:\n",
    "                for x in bm:\n",
    "                    utime += x.ru_utime\n",
    "                    stime += x.ru_stime\n",
    "                    maxrss = max(maxrss, x.ru_maxrss)\n",
    "            f.write('%s\\t%.3f\\t%.3f\\t%i\\n' % (key, utime, stime, maxrss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read configuration\n",
    "global cfg\n",
    "cfg = Configuration()\n",
    "config_fp = 'config.txt'\n",
    "if isfile(config_fp):\n",
    "    read_config(config_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process configuration\n",
    "if cfg.cpus == 0:\n",
    "    cfg.cpus = mp.cpu_count()\n",
    "if cfg.intermdir == '':\n",
    "    cfg.intermdir = join(cfg.wkdir, 'interm')\n",
    "if not isdir(cfg.intermdir):\n",
    "    makedirs(cfg.intermdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Infer protein-coding genes from genomes, using Prodigal\n",
    "Input: Genome sequences (`G#.fna`)\n",
    "\n",
    "Output: Protein sequences per genome (`G#.faa`)\n",
    "\n",
    "Intermediate files:\n",
    " - Protein sequences per genome (`G#.faa`)\n",
    " - Protein-coding sequences per genome (`G#.ffn`)\n",
    " - Genome annotation tables (`G#.gff`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_prodigal(fna_fp, faa_fp, ffn_fp, gff_fp, title=None):\n",
    "    \"\"\"Run prodigal to predict protein-coding genes of the genome.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fna_fp : str\n",
    "        file path to input genome sequence in FASTA format\n",
    "    faa_fp : str\n",
    "        file path to output protein sequences in FASTA format\n",
    "    ffn_fp : str\n",
    "        file path to output nucleotide sequences in FASTA format\n",
    "    gff_fp : str\n",
    "        file path to output genome annotation table in GFF3 format\n",
    "    title : str\n",
    "        title of the task to display (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resource usage object\n",
    "        resource usage information of this prodigal run\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        print('Running Prodigal on %s...' % title)\n",
    "    cmd = ('%s %s | %s -c -q -f gff -a %s -d %s -o %s'\n",
    "           % (cat(fna_fp), fna_fp, cfg.prodigal, faa_fp, ffn_fp, gff_fp))\n",
    "    return bench(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not check_dir('proteins'):\n",
    "    makedirs(join(cfg.intermdir, 'prodigal'))\n",
    "    for dname in 'faa', 'ffn', 'gff':\n",
    "        makedirs(join(cfg.intermdir, 'prodigal', dname))\n",
    "    bms = {}\n",
    "    pool = mp.Pool(cfg.cpus)\n",
    "    for fname in listdir(cfg.genomes_dir):\n",
    "        l = fname.split('.')\n",
    "        if 'fna' in l:\n",
    "            gid = '.'.join(l[0:l.index('fna')])\n",
    "            args = [join(cfg.genomes_dir, fname)]\n",
    "            for dname in 'faa', 'ffn', 'gff':\n",
    "                args.append(join(cfg.intermdir, 'prodigal', dname,\n",
    "                                 '%s.%s' % (gid, dname)))\n",
    "            args.append(gid)\n",
    "            bms[gid] = pool.apply_async(run_prodigal, args=args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for gid in bms:\n",
    "        bms[gid] = bms[gid].get()\n",
    "        faa_fp = join(cfg.intermdir, 'prodigal', 'faa', '%s.faa' % gid)\n",
    "        if isfile(faa_fp):\n",
    "            symlink(faa_fp, join(cfg.proteins_dir, '%s.faa' % gid))\n",
    "    write_benchmarks(bms, join(cfg.intermdir, 'prodigal', 'benchmark.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2: Extract marker genes and build species tree, using PhyloPhlAn\n",
    "Input: Protein sequences per genome (`G#.faa`).\n",
    "\n",
    "Output: Species tree\n",
    "\n",
    "Intermediate files:\n",
    " - Protein sequences per marker (`p###.faa`).\n",
    " - Alignments of protein sequences per marker (`p###.aln`).\n",
    " - Protein-to-marker dictionaries (`G#.b6o`).\n",
    " - Marker-to-proteins dictionary (`up2prots.txt`).\n",
    " - Genome-to-proteins dictionary (`orgs2prots.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not check_file('species_tree.nwk'):\n",
    "    pwd = getcwd()\n",
    "    cur_dir = join(cfg.intermdir, 'phylophlan')\n",
    "    makedirs(cur_dir)\n",
    "    for dname in 'input', 'output', 'temp':\n",
    "        makedirs(join(cur_dir, dname))\n",
    "    symlink(cfg.phylophlan_data_dir, join(cur_dir, 'data'))\n",
    "    symlink(cfg.proteins_dir, join(cur_dir, 'input', 'all'))\n",
    "    chdir(cur_dir)\n",
    "    cmd_fp = join(cfg.wkdir, 'tmp.sh')\n",
    "    with open(cmd_fp, 'w') as f:\n",
    "        f.write('source activate %s\\n' % cfg.py2_env)\n",
    "        f.write('%s -u all --nproc %s --c_dat temp\\n'\n",
    "                % (join(phylophlan_dir, 'phylophlan.py'), cfg.cpus))\n",
    "        f.write('source deactivate\\n')\n",
    "    print('Running PhyloPhlAn...')\n",
    "    bms = {'all': bench('bash %s' % cmd_fp, True)}\n",
    "    symlink(join(cur_dir, 'output', 'all', 'all.tree.nwk'), cfg.species_tree_fp)\n",
    "    write_benchmarks(bms, join(cur_dir, 'benchmark.txt'))\n",
    "    remove(cmd_fp)\n",
    "    chdir(pwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 3: Identify gene families using HMMER against Pfam\n",
    "Input: Protein sequences per genome (`G#.faa`).\n",
    "\n",
    "Output:\n",
    " - Protein sequences per family (`PF#####.#.faa`).\n",
    " - Statistics of families (`statistics.txt`).\n",
    "\n",
    "Intermediate files: HMMER search tabular reports (`G#.hm3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_hmmsearch(hmmfile, seqdb, outfile, title=None):\n",
    "    \"\"\"Run hmmsearch to search profiles within sequence database\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hmmfile : str\n",
    "        file path to database containing HMM profiles of reference protein\n",
    "        families (e.g., Pfam)\n",
    "    seqdb : str\n",
    "        file path to query protein sequences in FASTA format\n",
    "    outfile : str\n",
    "        output file in standard HMMER3 tabular format, fields:\n",
    "            target name, accession, tlen, query name, accession, qlen,\n",
    "            full sequence: E-value, score, bias, #, of\n",
    "            this domain: c-Evalue, i-Evalue, score, bias\n",
    "            hmm_coord: from, to\n",
    "            ali_coord: from, to\n",
    "            env_coord: from, to\n",
    "            acc, description of target\n",
    "    title : str\n",
    "        title of the task to display (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resource usage object\n",
    "        resource usage information of this hmmsearch run\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        print('Running hmmsearch on %s...' % title)\n",
    "    cmd = ('%s --notextw --noali --cut_ga --cpu 1 --domtblout %s %s %s > /dev/null'\n",
    "           % (cfg.hmmsearch, outfile, hmmfile, seqdb))\n",
    "    return bench(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not check_dir('gene_families'):\n",
    "    makedirs(join(cfg.intermdir, 'pfam'))\n",
    "    bms = {}\n",
    "    pool = mp.Pool(cfg.cpus)\n",
    "    for fname in listdir(cfg.proteins_dir):\n",
    "        if fname.endswith('.faa'):\n",
    "            gid = fname[:-4]\n",
    "            args = (cfg.pfam_db,\n",
    "                    join(cfg.proteins_dir, '%s.faa' % gid),\n",
    "                    join(cfg.intermdir, 'pfam', '%s.hm3' % gid),\n",
    "                    gid)\n",
    "            bms[gid] = pool.apply_async(run_hmmsearch, args=args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for gid in bms:\n",
    "        bms[gid] = bms[gid].get()\n",
    "    write_benchmarks(bms, join(cfg.intermdir, 'pfam', 'benchmark.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_hm3(hm3_fp, multi_assign=True, evalue=None,\n",
    "              plen=None, dlen=None, pcov=None, dcov=None):\n",
    "    \"\"\"Parse HMMER result to identify protein-to-domain matches.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hm3_fp : str\n",
    "        file path to input HMMER tabular report\n",
    "    multi_assign : bool\n",
    "        whether one protein can be associated with multiple domains (default: True)\n",
    "    evalue : float\n",
    "        full sequence E-value cutoff (optional)\n",
    "    plen : int\n",
    "        protein sequence length cutoff (optional)\n",
    "    dlen : int\n",
    "        domain profile length cutoff (optional)\n",
    "    pcov : float\n",
    "        protein sequence percent coverage cutoff (optional)\n",
    "    dcov : float\n",
    "        domain profile percent coverage cutoff (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple of 2 dicts of set of str\n",
    "        domain-to-proteins dictionary\n",
    "        protein-to-domains dictionary\n",
    "    \"\"\"\n",
    "    dom2prots, prot2doms = {}, {}\n",
    "    min_evalue = {}\n",
    "    with open(hm3_fp, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            l = line.strip().split()\n",
    "            if evalue and float(l[6]) > evalue:\n",
    "                continue\n",
    "            if plen and int(l[2]) < plen:\n",
    "                continue\n",
    "            if dlen and int(l[5]) < dlen:\n",
    "                continue\n",
    "            if pcov and (int(l[18]) - int(l[17]) + 1) / float(l[2]) * 100 < pcov:\n",
    "                continue\n",
    "            if dcov and (int(l[16]) - int(l[15]) + 1) / float(l[5]) * 100 < dcov:\n",
    "                continue\n",
    "            prot, dom = l[0], l[4]\n",
    "            if prot not in min_evalue or min_evalue[prot][1] > float(l[6]):\n",
    "                min_evalue[prot] = (dom, float(l[6]))\n",
    "            if prot in prot2doms:\n",
    "                prot2doms[prot].add(dom)\n",
    "            else:\n",
    "                prot2doms[prot] = set([dom])\n",
    "            if dom in dom2prots:\n",
    "                dom2prots[dom].add(prot)\n",
    "            else:\n",
    "                dom2prots[dom] = set([prot])\n",
    "            if multi_assign == False:\n",
    "                for prot in prot2doms:\n",
    "                    prot2doms[prot] = set([min_evalue[prot][0]])\n",
    "    return (dom2prots, prot2doms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not listdir(cfg.gene_families_dir) and isdir(join(cfg.intermdir, 'pfam')):\n",
    "    fam2prots = {}\n",
    "    fam2gs = {}\n",
    "    for fname in listdir(join(cfg.intermdir, 'pfam')):\n",
    "        if fname.endswith('.hm3'):\n",
    "            gid = fname[:-4]\n",
    "            print('Inferring gene families for %s...' % gid)\n",
    "            f2p = parse_hm3(join(cfg.intermdir, 'pfam', fname), evalue=1e-50, dcov=90)[0]\n",
    "            prots = {x.metadata['id']: x for x in\n",
    "                     io.read(join(cfg.proteins_dir, '%s.faa' % gid), format='fasta')}\n",
    "            for fam in f2p:\n",
    "                # optional: only keep single-copy genes\n",
    "                # if len(f2p[fam]) > 1:\n",
    "                #     continue\n",
    "                prots2add = [prots[x] for x in prots if x in f2p[fam]]\n",
    "                if fam in fam2prots:\n",
    "                    fam2prots[fam] += prots2add\n",
    "                    fam2gs[fam].add(gid)\n",
    "                else:\n",
    "                    fam2prots[fam] = prots2add\n",
    "                    fam2gs[fam] = set([gid])\n",
    "    stats = []\n",
    "    for fam, prots in fam2prots.items():\n",
    "        # families represented in <10 genomes are excluded\n",
    "        if len(fam2gs[fam]) < 10:\n",
    "            continue\n",
    "        print('Writing gene family %s...' % fam)\n",
    "        def outprots():\n",
    "            for prot in prots:\n",
    "                prot.metadata.pop('description', None)\n",
    "                yield prot\n",
    "        io.write(outprots(), format='fasta', into=join(cfg.gene_families_dir, '%s.faa' % fam))\n",
    "        stats.append([fam, len(fam2gs[fam]), len(prots)])\n",
    "    df = pd.DataFrame(stats, columns=['family', 'genomes', 'proteins'])\n",
    "    df.set_index('family', inplace=True)\n",
    "    df.sort_values(by=['genomes', 'proteins'], ascending=[False, False], inplace=True)\n",
    "    df.to_csv(join(cfg.gene_families_dir, 'statistics.txt'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build gene family trees, using Phylomizer\n",
    "Input: Protein sequences per family (`PF#.faa`).\n",
    "\n",
    "Output:\n",
    " - Gene tree per family (`PF#.nwk`).\n",
    "\n",
    "Intermediate files:\n",
    " - Clean alignment of protein sequences per family in Phylip (`PF#.alg.clean`) and FASTA (`PF#.alg.clean.fa`) formats.\n",
    " - Maximum likelihood gene family trees using WAG or JTT models in Newick format (`PF#.tree.fasttree.ml.wag/jtt.nw`).\n",
    " - Ranking of per-model log likelihoods (`PF#.tree.fasttree.rank.ml`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Phylomizer configuration file, inherited from the \"KMM\" protocol,\n",
    "# except for that PhyML is replaced by FastTree\n",
    "pcfg = \"\"\"\n",
    "verbose             parameter    1\n",
    "residue_datatype    parameter    protein\n",
    "force_seed_sequence parameter    True\n",
    "alignment           mode         kalign muscle mafft\n",
    "consensus           mode         m_coffee\n",
    "trimming            mode         trimal\n",
    "both_direction      parameter    True\n",
    "min_seqs            parameter    10\n",
    "in_letter           parameter    U:B\n",
    "in_letter           parameter    O:Z\n",
    "muscle              binary       %s\n",
    "muscle_params       parameter    \n",
    "mafft               binary       %s\n",
    "mafft_params        parameter    --auto\n",
    "kalign              binary       %s\n",
    "kalign_params       parameter    -f fasta\n",
    "m_coffee            binary       %s\n",
    "m_coffee_params     parameter    -n_core 1 -output fasta -quiet\n",
    "trimal              binary       %s\n",
    "trimal_params       parameter    -phylip -gt 0.1\n",
    "trimal_compare      parameter    -ct 0.1667\n",
    "readal              binary       %s\n",
    "tree                mode         fasttree\n",
    "evol_models         parameter    wag jtt\n",
    "numb_models         parameter    2\n",
    "tree_approach       mode         ml\n",
    "ml                  parameter    \n",
    "fasttree            binary       %s\n",
    "fasttree_params     parameter    -gamma\n",
    "\"\"\" % (cfg.muscle, cfg.mafft, cfg.kalign, cfg.t_coffee, cfg.trimal,\n",
    "       cfg.readal, cfg.fasttree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_phylomizer(faa_fp, cfg_fp, out_dir, title=None):\n",
    "    \"\"\"Run Phylomizer to build phylogenetic tree of a gene family.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    faa_fp : str\n",
    "        file path to input protein sequences in FASTA format\n",
    "    cfg_fp : str\n",
    "        file path to Phylomizer configuration\n",
    "    out_dir : str\n",
    "        path to output directory\n",
    "    title : str\n",
    "        title of the task to display (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resource usage object\n",
    "        resource usage information of this Phylomizer run\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        print('Running Phylomizer on %s...' % title)\n",
    "    f, fp = mkstemp()\n",
    "    close(f)\n",
    "    with open(fp, 'w') as f:\n",
    "        f.write('source activate %s\\n' % cfg.py2_env)\n",
    "        f.write('%s -i %s --steps alignments trees -c %s -o %s\\n'\n",
    "                % (cfg.phylomizer, faa_fp, cfg_fp, out_dir))\n",
    "        f.write('source deactivate\\n')\n",
    "    bm = bench('bash %s' % fp)\n",
    "    remove(fp)\n",
    "    return bm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not check_dir('gene_trees'):\n",
    "    makedirs(join(cfg.intermdir, 'phylomizer'))\n",
    "    with open(join(cfg.intermdir, 'phylomizer', 'config.txt'), 'w') as f:\n",
    "        f.write(pcfg.strip())\n",
    "    bms = {}\n",
    "    pool = mp.Pool(cfg.cpus)\n",
    "    for fname in listdir(cfg.gene_families_dir):\n",
    "        if fname.endswith('.faa'):\n",
    "            fid = fname[:-4]\n",
    "            args = (join(cfg.gene_families_dir, fname),\n",
    "                    join(cfg.intermdir, 'phylomizer', 'config.txt'),\n",
    "                    join(cfg.intermdir, 'phylomizer', fid),\n",
    "                    fid)\n",
    "            bms[fid] = pool.apply_async(run_phylomizer, args=args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for fid in bms:\n",
    "        bms[fid] = bms[fid].get()\n",
    "        fid_stem = fid.split('.')[0]\n",
    "        res_dir = join(cfg.intermdir, 'phylomizer', fid)\n",
    "        ml_fp = join(res_dir, '%s.tree.fasttree.rank.ml' % fid_stem)\n",
    "        if isfile(ml_fp):\n",
    "            with open(ml_fp, 'r') as f:\n",
    "                models = dict([x.split() for x in f.read().splitlines()])\n",
    "            if models:\n",
    "                # select the best model, which has the highest log likelihood\n",
    "                best_model = sorted(models.items(),\n",
    "                                    key=lambda x: float(x[1]), reverse=True)[0][0]\n",
    "                best_tree_fp = join(res_dir, '%s.tree.fasttree.ml.%s.nw'\n",
    "                                    % (fid_stem, best_model.lower()))\n",
    "                symlink(best_tree_fp, join(cfg.gene_trees_dir, '%s.nwk' % fid))\n",
    "    write_benchmarks(bms, join(cfg.intermdir, 'phylomizer', 'benchmark.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Inferring horizontal gene transfers, using Ranger-DTL\n",
    "Input:\n",
    " - Species tree (`species_tree.nwk`).\n",
    " - Gene family trees (`PF#.nwk`).\n",
    "\n",
    "Output:\n",
    " - Reconciliation result per gene family (`PF#/reconc.txt`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_rangerdtl(input_fp, result_dir, reps=100, cutoff=0.75, title=None):\n",
    "    \"\"\"Run RANGER-DTL to infer non-vertical evolutionary history of a gene family.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_fp : str\n",
    "        input file path (species tree followed by gene tree)\n",
    "    result_dir : str\n",
    "        directory to save intermediate files\n",
    "    reps : int\n",
    "        number of replicates to run (default: 100)\n",
    "    cutoff : float\n",
    "        probability cutoff for reporting HGT events\n",
    "    title : str\n",
    "        title of the task to display (optional)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of resource usage objects\n",
    "        resource usage information of these OptRoot, Ranger-DTL and\n",
    "        AggregateRanger runs\n",
    "    \"\"\"\n",
    "    if title:\n",
    "        print('Running Ranger-DTL on %s...' % title)\n",
    "\n",
    "    # read species tree\n",
    "    with open(input_fp, 'r') as f:\n",
    "        stree_str = f.readline().rstrip('\\r\\n')\n",
    "\n",
    "    # run OptRoot\n",
    "    # \"-r --seed n\" will print only one optimal rooting out of multiple\n",
    "    cmd = ('%s -i %s -o %s -r --seed 1'\n",
    "           % (cfg.optroot, input_fp, join(result_dir, 'optroot.txt')))\n",
    "    bms = [bench(cmd)]\n",
    "    \n",
    "    # read (first) optimal rooting\n",
    "    gtree_str = ''\n",
    "    with open(join(result_dir, 'optroot.txt'), 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\r\\n')\n",
    "            if line and not line.startswith(' '):\n",
    "                gtree_str = line\n",
    "                break\n",
    "\n",
    "    # create new input file\n",
    "    f, tmp_fp = mkstemp()\n",
    "    close(f)\n",
    "    with open(tmp_fp, 'w') as f:\n",
    "        f.write('%s\\n' % stree_str)\n",
    "        f.write('%s\\n' % gtree_str)\n",
    "\n",
    "    # run Ranger-DTL for 100 times\n",
    "    for i in range(reps):\n",
    "        cmd = ('%s -i %s -o %s --seed %d'\n",
    "               % (cfg.rangerdtl, tmp_fp, join(result_dir, 'reconc%d' % i), i))\n",
    "        bms.append(bench(cmd))\n",
    "    remove(tmp_fp)\n",
    "\n",
    "    # run AggregateRanger\n",
    "    cmd = ('%s %s > %s' % (cfg.aggregateranger, join(result_dir, 'reconc'),\n",
    "                           join(result_dir, 'aggreconc.txt')))\n",
    "    bms.append(bench(cmd))\n",
    "\n",
    "    # generate report\n",
    "    recipients = {}\n",
    "    # in each reconciliation file, an HGT record line reads like:\n",
    "    # m4 = LCA[G000008625, G000196115_1]: Transfer, Mapping --> G000008625, Recipient --> G000196115            \n",
    "    p = re.compile(r'^(.+) = (.+): Transfer, Mapping --> (.+), Recipient --> (.+)$')\n",
    "    for i in range(reps):\n",
    "        with open(join(result_dir, 'reconc%d' % i), 'r') as f:\n",
    "            for line in f:\n",
    "                line = line.rstrip('\\r\\n')\n",
    "                m = p.search(line)\n",
    "                if m:\n",
    "                    donor, recipient = m.group(1), m.group(4)\n",
    "                    if donor not in recipients:\n",
    "                        recipients[donor] = {recipient: 1}\n",
    "                    elif recipient not in recipients[donor]:\n",
    "                        recipients[donor][recipient] = 1\n",
    "                    else:\n",
    "                        recipients[donor][recipient] += 1\n",
    "    top_recipient = {}\n",
    "    for donor in recipients:\n",
    "        for recipient in sorted(recipients[donor], key=recipients[donor].get, reverse=True):\n",
    "            top_recipient[donor] = (recipient, recipients[donor][recipient])\n",
    "            break\n",
    "    # cutoffs = {'transfer': 75, 'donor': 90, 'recipient': 90}\n",
    "    # in the aggregated reconciliation file, an HGT record line reads like:\n",
    "    # m2 = LCA[G000008625, G000013045]: [Speciations = 35, Duplications = 0, Transfers = 65], [Most Frequent mapping --> G000013045, 48 times].\n",
    "    dups, hgts = [], []\n",
    "    p = re.compile(r'^(.+) = (.+): \\[Speciations = (\\d+), Duplications = (\\d+), Transfers = (\\d+)\\], \\[Most Frequent mapping --> (.+), (\\d+) times\\]')\n",
    "    with open(join(result_dir, 'aggreconc.txt'), 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\r\\n')\n",
    "            m = p.search(line)\n",
    "            if m:\n",
    "                donor, n_dup, n_hgt, mapping, n_mapping = m.group(1), int(m.group(4)), int(m.group(5)), m.group(6), int(m.group(7))\n",
    "                if n_dup > 0:\n",
    "                    dup_support = (1.0 * n_dup * n_mapping) / (reps ** 2)\n",
    "                    if dup_support >= cutoff:\n",
    "                        dups.append((mapping, dup_support))\n",
    "                if n_hgt > 0:\n",
    "                    hgt_support = (1.0 * n_hgt * n_mapping * top_recipient[donor][1]) / (reps ** 3)\n",
    "                    if hgt_support >= cutoff:\n",
    "                        hgts.append((mapping, top_recipient[donor][0], hgt_support))\n",
    "    if dups:\n",
    "        with open(join(result_dir, 'duplications.txt'), 'w') as f:\n",
    "            for dup in dups:\n",
    "                # node, support\n",
    "                f.write('%s\\t%.3f\\n' % (dup[0], dup[1]))\n",
    "    if hgts:\n",
    "        with open(join(result_dir, 'transfers.txt'), 'w') as f:\n",
    "            for hgt in hgts:\n",
    "                # donor, recipient, support\n",
    "                f.write('%s\\t%s\\t%.3f\\n' % (hgt[0], hgt[1], hgt[2]))\n",
    "\n",
    "    # clean up\n",
    "    with tarfile.open(join(result_dir, 'reconcs.tar.gz'), 'w:gz') as tar:\n",
    "        for i in range(reps):\n",
    "            tar.add(join(result_dir, 'reconc%d' % i), arcname=('reconc%d' % i))\n",
    "    for i in range(reps):\n",
    "        remove(join(result_dir, 'reconc%d' % i))\n",
    "    return bms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_protein_to_genome():\n",
    "    \"\"\"Generate a protein ID to genome ID dictionary.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict of str\n",
    "        protein ID to genome ID\n",
    "    \"\"\"\n",
    "    prot2g = {}\n",
    "    for fname in listdir(cfg.proteins_dir):\n",
    "        if fname.endswith('.faa'):\n",
    "            gid = fname[:-4]\n",
    "            with open(join(cfg.proteins_dir, fname)) as f:\n",
    "                for line in f:\n",
    "                    if line.startswith('>'):\n",
    "                        prot = line[1:].split()[0]\n",
    "                        prot2g[prot] = gid\n",
    "    return prot2g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not check_dir('gene_networks'):\n",
    "    makedirs(join(cfg.intermdir, 'ranger-dtl'))\n",
    "    prot2g = get_protein_to_genome()\n",
    "\n",
    "    # reformat species tree\n",
    "    # replace nodal support values with incremental node indices\n",
    "    stree = TreeNode.read(cfg.species_tree_fp)\n",
    "    gids = set()\n",
    "    idx, nodes, edges = 0, [], []\n",
    "    for node in stree.levelorder():\n",
    "        if node.is_tip():  # terminal tip\n",
    "            gids.add(node.name)\n",
    "        else:  # internal node\n",
    "            support = node.name if node.name is not None else ''\n",
    "            node.name = 'n%s' % idx\n",
    "            idx += 1\n",
    "            nodes.append((node.name, support))\n",
    "        if node.parent is not None:  # non-root\n",
    "            edges.append((node.parent.name, node.name, node.length))\n",
    "\n",
    "    # export Cytoscape-compatible network files\n",
    "    with open(join(cfg.wkdir, 'species_tree.nodes'), 'w') as f:\n",
    "        f.write('%s\\n' % '\\t'.join(('name', 'support')))\n",
    "        for node in nodes:\n",
    "            f.write('%s\\t%s\\n' % (node[0], node[1]))\n",
    "    with open(join(cfg.wkdir, 'species_tree.edges'), 'w') as f:\n",
    "        f.write('%s\\n' % '\\t'.join(('source', 'target', 'interaction', 'directed', 'length')))\n",
    "        for edge in edges:\n",
    "            f.write('%s\\t%s\\tV\\tTRUE\\t%.5f\\n' % (edge[0], edge[1], edge[2]))\n",
    "            \n",
    "    # Ranger-DTL cannot parse branch lengths as scientific notations\n",
    "    # change them into zero\n",
    "    sci = re.compile(r':-?[0-9\\.]+e-[0-9]+([,;\\)])')\n",
    "    stree_str = str(stree).replace('\\'', '')\n",
    "    stree_str = re.sub(sci, r':0.0\\1', stree_str)\n",
    "    with open(join(cfg.intermdir, 'ranger-dtl', 'species_tree_labeled.nwk'), 'w') as f:\n",
    "        f.write(stree_str)\n",
    "\n",
    "    fid2gid2n = {}\n",
    "    \n",
    "    bms = {}\n",
    "    pool = mp.Pool(cfg.cpus)\n",
    "    for fname in listdir(cfg.gene_trees_dir):\n",
    "        if fname.endswith('.nwk'):\n",
    "            fid = fname[:-4]\n",
    "\n",
    "            # reformat input file\n",
    "            gtree = TreeNode.read(join(cfg.gene_trees_dir, fname),\n",
    "                                  convert_underscores=False)\n",
    "            gtree.bifurcate()\n",
    "            for node in gtree.non_tips():\n",
    "                node.name = ''\n",
    "            gid2n = {}\n",
    "            for node in gtree.tips():\n",
    "\n",
    "                # replace protein ID with host genome ID\n",
    "                gid = prot2g[node.name]\n",
    "\n",
    "                # if multiple family members are present in one genome,\n",
    "                # add suffix \"_1\", \"_2\",...\n",
    "                if gid in gid2n:\n",
    "                    node.name = '%s_%s' % (gid, gid2n[gid])\n",
    "                    gid2n[gid] += 1\n",
    "                else:\n",
    "                    node.name = gid\n",
    "                    gid2n[gid] = 1\n",
    "\n",
    "            fid2gid2n[fid] = gid2n\n",
    "            gtree_str = str(gtree).replace('\\'', '')\n",
    "            gtree_str = re.sub(sci, r':0.0\\1', gtree_str)\n",
    "\n",
    "            # prune species tree so that only tips present in a gene tree\n",
    "            # are retained\n",
    "            sub_stree = stree.copy()\n",
    "            ntips = len(gid2n)\n",
    "            while True:\n",
    "                sub_stree.remove_deleted(lambda x: x.is_tip()\n",
    "                                         and x.name not in gid2n)\n",
    "                sub_stree.prune()\n",
    "                if len([n.name for n in sub_stree.tips()]) == ntips:\n",
    "                    break\n",
    "            sub_stree_str = str(sub_stree).replace('\\'', '')\n",
    "            sub_stree_str = re.sub(sci, r':0.0\\1', sub_stree_str)\n",
    "\n",
    "            res_dir = join(cfg.intermdir, 'ranger-dtl', fid)\n",
    "            makedirs(res_dir)\n",
    "            input_fp = join(res_dir, 'input.txt')\n",
    "            with open(input_fp, 'w') as f:\n",
    "                f.write(sub_stree_str)\n",
    "                f.write(gtree_str)\n",
    "            args = (input_fp, res_dir, 100, 0.75, fid)\n",
    "            bms[fid] = pool.apply_async(run_rangerdtl, args=args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    for fid in bms:\n",
    "        bms[fid] = bms[fid].get()\n",
    "        with open(join(cfg.gene_networks_dir, '%s.edges' % fid), 'w') as fo:\n",
    "            with open(join(cfg.wkdir, 'species_tree.edges'), 'r') as fi:\n",
    "                line = fi.readline().rstrip('\\r\\n')\n",
    "                fo.write('%s\\tsupport\\n' % line)\n",
    "                for line in fi:\n",
    "                    fo.write('%s\\t\\n' % line.rstrip('\\r\\n'))\n",
    "            res_fp = join(cfg.intermdir, 'ranger-dtl', fid, 'transfers.txt')\n",
    "            if isfile(res_fp):\n",
    "                with open(res_fp, 'r') as fi:\n",
    "                    for line in fi:\n",
    "                        l = line.rstrip('\\r\\n').split('\\t')\n",
    "                        fo.write('%s\\t%s\\tH\\tTRUE\\t\\t%s\\n' % (l[0], l[1], l[2]))\n",
    "        with open(join(cfg.gene_networks_dir, '%s.nodes' % fid), 'w') as f:\n",
    "            f.write('%s\\n' % '\\t'.join(('name', 'support', 'copies', 'duplications')))\n",
    "            dups = {}\n",
    "            res_fp = join(cfg.intermdir, 'ranger-dtl', fid, 'duplications.txt')\n",
    "            if isfile(res_fp):\n",
    "                with open(res_fp, 'r') as fi:\n",
    "                    for line in fi:\n",
    "                        node = line.rstrip('\\r\\n').split('\\t')[0]\n",
    "                        if node in dups:\n",
    "                            dups[node] += 1\n",
    "                        else:\n",
    "                            dups[node] = 1\n",
    "            for gid in gids:\n",
    "                n_copy = fid2gid2n[fid][gid] if gid in fid2gid2n[fid] else 0\n",
    "                n_dup = dups[gid] if gid in dups else 0\n",
    "                f.write('%s\\t\\t%d\\t%d\\n' % (gid, n_copy, n_dup))\n",
    "            for node in nodes:\n",
    "                n_dup = dups[node[0]] if node[0] in dups else 0\n",
    "                f.write('%s\\t%s\\t\\t%d\\n' % (node[0], node[1], n_dup))\n",
    "    write_benchmarks(bms, join(cfg.intermdir, 'ranger-dtl', 'benchmark.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_table(join(cfg.wkdir, 'taxonomy.txt'), index_col='name')\n",
    "gid2species = {}\n",
    "for gid in taxonomy.index.tolist():\n",
    "    gid2species[gid] = taxonomy['species'][gid].replace('_', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "families = {}\n",
    "with open(join(cfg.wkdir, 'pfam.txt'), 'r') as f:\n",
    "    for line in f:\n",
    "        l = line.rstrip('\\r\\n').split('\\t')\n",
    "        families[l[0]] = l[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(join(cfg.wkdir, 'species_tree.cyjs'), 'r') as f:\n",
    "    species_cyjs = json.loads(f.read())\n",
    "node2suid = {}\n",
    "for node in species_cyjs['elements']['nodes']:\n",
    "    node2suid[node['data']['name']] = node['data']['SUID']\n",
    "used_suids = set()\n",
    "for e in 'edges', 'nodes':\n",
    "    for element in species_cyjs['elements'][e]:\n",
    "        used_suids.add(int(element['data']['SUID']))\n",
    "start_idx = max(used_suids) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fid in listdir(join(cfg.intermdir, 'ranger-dtl')):\n",
    "    if not isdir(join(cfg.intermdir, 'ranger-dtl', fid)):\n",
    "        continue\n",
    "    hgts = []\n",
    "    res_fp = join(cfg.intermdir, 'ranger-dtl', fid, 'transfers.txt')\n",
    "    if isfile(res_fp):\n",
    "        with open(res_fp, 'r') as f:\n",
    "            hgts = [x.split('\\t') for x in f.read().splitlines()]\n",
    "    tips, copies, dups = set(), {}, {}\n",
    "    with open(join(cfg.gene_networks_dir, '%s.nodes' % fid), 'r') as f:\n",
    "        next(f)\n",
    "        for line in f:\n",
    "            l = line.rstrip('\\r\\n').split('\\t')\n",
    "            if l[1] == '' and l[2] != '':\n",
    "                tips.add(l[0])\n",
    "            if l[2] and l[2] != '0':\n",
    "                copies[l[0]] = int(l[2])\n",
    "            if l[3] and l[3] != '0':\n",
    "                dups[l[0]] = int(l[3])\n",
    "    gene_cyjs = deepcopy(species_cyjs)\n",
    "    title = '%s (%s)' % (fid, families[fid]) if fid in families else fid\n",
    "    gene_cyjs['data']['name'] = title\n",
    "    gene_cyjs['data']['shared_name'] = title\n",
    "    for node in gene_cyjs['elements']['nodes']:\n",
    "        nid = node['data']['name']\n",
    "        if nid in tips:\n",
    "            node['data']['species'] = gid2species[nid]\n",
    "            node['data']['tip'] = 'TRUE'\n",
    "        if nid in copies:\n",
    "            node['data']['copies'] = copies[nid]\n",
    "        if nid in dups:\n",
    "            node['data']['duplications'] = dups[nid]\n",
    "    i = start_idx\n",
    "    for hgt in hgts:\n",
    "        gene_cyjs['elements']['edges'].append({'data': {\n",
    "            'SUID': i,\n",
    "            'directed': True,\n",
    "            'id': str(i),\n",
    "            'interaction': 'H',\n",
    "            'name': '%s (H) %s' % (hgt[0], hgt[1]),\n",
    "            'selected': False,\n",
    "            'shared_interaction': 'H',\n",
    "            'shared_name': '%s (H) %s' % (hgt[0], hgt[1]),\n",
    "            'source': str(node2suid[hgt[0]]),\n",
    "            'target': str(node2suid[hgt[1]]),\n",
    "            'support': float(hgt[2])}, 'selected': False})\n",
    "        i += 1\n",
    "    with open(join(cfg.gene_networks_dir, '%s.cyjs' % fid), 'w') as f:\n",
    "        json.dump(gene_cyjs, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for fid in listdir(join(cfg.intermdir, 'ranger-dtl')):\n",
    "    res_dir = join(cfg.intermdir, 'ranger-dtl', fid)\n",
    "    if isdir(res_dir):\n",
    "        res_fp = join(res_dir, 'hgts.txt')\n",
    "        if isfile(res_fp):\n",
    "            with open(join(cfg.gene_networks_dir, '%s.edges' % fid), 'w') as fo:\n",
    "                with open(join(cfg.wkdir, 'species_tree.edges'), 'r') as fi:\n",
    "                    line = fi.readline.rstrip('\\r\\n')\n",
    "                    fo.write('%s\\tsupport\\n' % line)\n",
    "                    for line in fi:\n",
    "                        fo.write('%s\\t\\n' % line.rstrip('\\r\\n'))\n",
    "                with open(res_fp, 'r') as fi:\n",
    "                    for line in fi:\n",
    "                        l = line.rstrip('\\r\\n').split('\\t')\n",
    "                        fo.write('%s\\t%s\\tH\\tTRUE\\t\\t%s\\n' % (l[0], l[1], l[2]))\n",
    "        gtree = TreeNode.read()\n",
    "        tips = set([x.name for x in tree.tips()])\n",
    "                with open(join(cfg.gene_networks_dir, '%s.nodes' % fid), 'w') as f:\n",
    "                    for tip in [x.name for x in stree.tips()]:\n",
    "                        isin = True if tip in tips else False\n",
    "                        f.write('%s\\t%s\\n' % (tip, str(isin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_rangerdtl_result(fname):\n",
    "    with open(fname, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.rstrip('\\r\\n')\n",
    "            if line.startswith('Species Tree:'):\n",
    "                line = next(f).rstrip('\\r\\n')\n",
    "                yield line\n",
    "            elif 'Transfer, Mapping' in line:\n",
    "                # m4 = LCA[G000008625, G000196115_1]: Transfer, Mapping --> G000008625, Recipient --> G000196115\n",
    "                l = line.split(': ')[-1].split(', ')\n",
    "                if l[-2].startswith('Mapping') and l[-1].startswith('Recipient'):\n",
    "                    donor, recipient = l[-2].split(' --> ')[1], l[-1].split(' --> ')[1]\n",
    "                    yield donor, recipient\n",
    "                # m2 = LCA[G000008625, G000013045]: [Speciations = 35, Duplications = 0, Transfers = 65], [Most Frequent mapping --> G000013045, 48 times]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vert_edges = []\n",
    "for node in stree.postorder(include_self=False):\n",
    "    vert_edges.append((node.parent.name, node.name))\n",
    "for fid in listdir(join(cfg.intermdir, 'ranger-dtl')):\n",
    "    if isdir(join(cfg.intermdir, 'ranger-dtl', fid)):\n",
    "        gen = parse_rangerdtl_result(join(cfg.intermdir, 'ranger-dtl',\n",
    "                                          fid, 'aggreconc.txt'))\n",
    "        tree = TreeNode.read([next(gen)])\n",
    "        nodes = list(gen)\n",
    "\n",
    "        hori_edges = []\n",
    "        for node in nodes:\n",
    "            d, r = node\n",
    "            sd, sr = tree.find(d), tree.find(r)\n",
    "            if sd.is_tip():\n",
    "                dlca = stree.find(sd.name).name\n",
    "            else:\n",
    "                sd_tips = list(sd.subset())\n",
    "                dlca = stree.lowest_common_ancestor(sd_tips).name\n",
    "            if sr.is_tip():\n",
    "                rlca = stree.find(sr.name).name\n",
    "            else:\n",
    "                sr_tips = list(sr.subset())\n",
    "                rlca = stree.lowest_common_ancestor(sr_tips).name\n",
    "            hori_edges.append((dlca, rlca))\n",
    "\n",
    "        edges = pd.DataFrame(hori_edges + vert_edges, columns=['source', 'target'])\n",
    "        edges['hgt'] = len(hori_edges) * [True] + len(vert_edges) * [False]\n",
    "        edges = edges.set_index('source')\n",
    "        edges.to_csv(join(cfg.gene_networks_dir, '%s.edges' % fid), sep='\\t')\n",
    "\n",
    "        edges = pd.DataFrame(hori_edges, columns=['source', 'target'])\n",
    "        edges['interaction'] = len(hori_edges) * ['H']\n",
    "        edges['directed'] = len(hori_edges) * ['TRUE']\n",
    "        edges['support'] = len(hori_edges) * ['H']\n",
    "\n",
    "        tips = set([x.name for x in tree.tips()])\n",
    "        with open(join(cfg.gene_networks_dir, '%s.nodes' % fid), 'w') as f:\n",
    "            for tip in [x.name for x in stree.tips()]:\n",
    "                isin = True if tip in tips else False\n",
    "                f.write('%s\\t%s\\n' % (tip, str(isin)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
